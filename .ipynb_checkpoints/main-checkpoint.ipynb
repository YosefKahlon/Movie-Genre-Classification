{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Project Machine Learning Course\n",
    "\n",
    "\n",
    "## Movie Genre Classification\n",
    "Dataset link: [Genre Classification Dataset - IMDb](https://www.kaggle.com/datasets/hijest/genre-classification-dataset-imdb/data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### We are tasked to classify genre to movie base on the description.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read the data using pandas\n",
    "\n",
    "train_path = 'Genre Classification Dataset/train_data.txt'\n",
    "train_data = pd.read_csv(train_path, delimiter=':::', engine='python', names=['ID', 'Title', 'Genre', 'Description'])\n",
    "\n",
    "test_path = 'Genre Classification Dataset/test_data_solution.txt'\n",
    "test_data = pd.read_csv(test_path, delimiter=':::', engine='python', names=['ID', 'Title', 'Genre', 'Description'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load dataset\n",
    "### Overview:\n",
    "\n",
    "The dataset is sourced from IMDb (Internet Movie Database),\n",
    "a comprehensive online database containing information about films, TV shows, videos, games, and streaming content.\n",
    "\n",
    "### Content:\n",
    "The dataset consists of two main components: train data and test data.\n",
    "\n",
    "* Train Data:\n",
    "\n",
    " - Each entry includes an ID, title, genre, and description.\n",
    " - The ID uniquely identifies each entry.\n",
    " - Title represents the name of the movie or TV show.\n",
    " - Genre specifies the category or categories to which the title belongs.\n",
    " - Description provides a brief overview or summary of the title's plot or content.\n",
    "\n",
    "Test Data:\n",
    "\n",
    "* Test Data:\n",
    "\n",
    "    - Similar to train data, each entry comprises an ID, title, genre, and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data\n",
      "(54214, 4)\n",
      "shape of test data\n",
      "(54200, 4)\n"
     ]
    }
   ],
   "source": [
    "# view the data\n",
    "print(\"shape of train data\")\n",
    "print(train_data.shape)\n",
    "\n",
    "print(\"shape of test data\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Oscar et la dame rose (2009)</td>\n",
       "      <td>drama</td>\n",
       "      <td>Listening in to a conversation between his do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cupid (1997)</td>\n",
       "      <td>thriller</td>\n",
       "      <td>A brother and sister with a past incestuous r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Young, Wild and Wonderful (1980)</td>\n",
       "      <td>adult</td>\n",
       "      <td>As the bus empties the students for their fie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>The Secret Sin (1915)</td>\n",
       "      <td>drama</td>\n",
       "      <td>To help their unemployed father make ends mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Unrecovered (2007)</td>\n",
       "      <td>drama</td>\n",
       "      <td>The film's title refers not only to the un-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Quality Control (2011)</td>\n",
       "      <td>documentary</td>\n",
       "      <td>Quality Control consists of a series of 16mm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Pink Slip\" (2009)</td>\n",
       "      <td>comedy</td>\n",
       "      <td>In tough economic times Max and Joey have all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>One Step Away (1985)</td>\n",
       "      <td>crime</td>\n",
       "      <td>Ron Petrie (Keanu Reeves) is a troubled teen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Desperate Hours\" (2016)</td>\n",
       "      <td>reality-tv</td>\n",
       "      <td>A sudden calamitous event, causing great loss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Spirits (2014/I)</td>\n",
       "      <td>horror</td>\n",
       "      <td>Four high school students embark on a terrify...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                               Title          Genre  \\\n",
       "0   1       Oscar et la dame rose (2009)          drama    \n",
       "1   2                       Cupid (1997)       thriller    \n",
       "2   3   Young, Wild and Wonderful (1980)          adult    \n",
       "3   4              The Secret Sin (1915)          drama    \n",
       "4   5             The Unrecovered (2007)          drama    \n",
       "5   6             Quality Control (2011)    documentary    \n",
       "6   7                 \"Pink Slip\" (2009)         comedy    \n",
       "7   8               One Step Away (1985)          crime    \n",
       "8   9           \"Desperate Hours\" (2016)     reality-tv    \n",
       "9  10                   Spirits (2014/I)         horror    \n",
       "\n",
       "                                         Description  \n",
       "0   Listening in to a conversation between his do...  \n",
       "1   A brother and sister with a past incestuous r...  \n",
       "2   As the bus empties the students for their fie...  \n",
       "3   To help their unemployed father make ends mee...  \n",
       "4   The film's title refers not only to the un-re...  \n",
       "5   Quality Control consists of a series of 16mm ...  \n",
       "6   In tough economic times Max and Joey have all...  \n",
       "7   Ron Petrie (Keanu Reeves) is a troubled teen ...  \n",
       "8   A sudden calamitous event, causing great loss...  \n",
       "9   Four high school students embark on a terrify...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Cleaning and Preprocessing\n",
    "We will clean and preprocess the data\n",
    "- Remove duplicates and NaN values.\n",
    "- Preprocess the text data (description) for better model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\97252\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\97252\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\97252\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "## Check for Duplicates and Remove them\n",
    "num = train_data.duplicated().sum()\n",
    "print(num)\n",
    "if num > 0:\n",
    "    train_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID             0\n",
      "Title          0\n",
      "Genre          0\n",
      "Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Check for nan values\n",
    "num = train_data.isna().sum()\n",
    "print(num)\n",
    "train_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'each', 'ours', 'he', 'had', 'here', 'does', 'no', 'herself', 'again', 'itself', 've', 'is', 'out', 'own', 'there', 'them', 'than', 'myself', 'y', 'my', 'below', 'just', 'were', 'during', 'yourselves', 'yourself', \"doesn't\", 'any', 'don', 'shan', 'few', 'me', 'both', 'nor', 'very', 'to', 'not', 'into', \"mightn't\", 'she', 'once', \"should've\", \"she's\", 'with', 're', \"you'll\", 'aren', 'too', \"that'll\", 'who', 'ma', 'your', 'so', 'did', 'same', 'ain', 'they', 'under', 'ourselves', 'where', 's', 'was', 'which', 'o', 'an', 'himself', 'between', 'all', \"it's\", 'hers', 'a', 'isn', \"needn't\", 'be', 'because', 'before', 'has', 'it', 'off', 'but', 'being', 'those', 'didn', 't', 'as', 'further', \"wouldn't\", 'through', 'most', 'him', 'on', 'when', \"couldn't\", 'having', 'these', 'hasn', 'some', \"didn't\", 'or', 'in', 'mightn', 'yours', 'doesn', \"won't\", 'haven', 'i', 'up', 'over', 'now', 'more', \"haven't\", 'her', 'and', 'for', 'then', 'won', 'd', \"weren't\", \"don't\", \"you're\", 'am', 'until', 'theirs', 'been', 'of', \"aren't\", 'will', 'weren', 'after', 'only', 'down', \"mustn't\", 'wasn', \"you'd\", 'its', \"you've\", 'do', 'why', 'you', 'above', \"hasn't\", \"isn't\", 'shouldn', 'by', \"shouldn't\", 'whom', 'needn', 'the', 'if', 'm', 'that', 'll', 'his', 'about', \"wasn't\", 'we', 'at', 'other', 'are', 'such', 'hadn', 'this', 'against', 'our', 'themselves', 'from', \"shan't\", 'while', 'couldn', 'what', 'have', \"hadn't\", 'mustn', 'wouldn', 'their', 'doing', 'how', 'can', 'should'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 49\u001b[0m\n\u001b[0;32m     43\u001b[0m     cleaned_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tokens)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cleaned_text\n\u001b[1;32m---> 49\u001b[0m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText_cleaning\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText_cleaning\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(clean_text)\n\u001b[0;32m     51\u001b[0m train_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[15], line 35\u001b[0m, in \u001b[0;36mclean_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     32\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Remove stopwords\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     36\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Lemmatization\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# lemmatizer = WordNetLemmatizer()\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# tokens = [lemmatizer.lemmatize(word) for word in tokens]\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Join tokens back into a single string\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PycharmProjects\\Movie Genre Classification\\Script\\lib\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m _path\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "\n",
    "#Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "\n",
    "#exmple for LancasterStemmer\n",
    "# words = ['sincerely','electricity','roughly','ringing']\n",
    "# Lanc = LancasterStemmer()\n",
    "# for w in words:\n",
    "#     print(w, \" : \", Lanc.stem(w))\n",
    "\n",
    "\n",
    "Lanc = LancasterStemmer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Expand contractions\n",
    "\n",
    "\n",
    "    # Remove URLs and email addresses\n",
    "    text = re.sub(r'\\b(?:https?://|www\\.)\\S+\\b', '', text)\n",
    "    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n",
    "\n",
    "    # Remove special characters, punctuation, and symbols\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize text\n",
    "    word_tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    word_tokens = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    # We found that it didn't improve accuracy and might have even reduced it.\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    # tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # Join tokens back into a single string\n",
    "    cleaned_text = ' '.join(word_tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "train_data['Text_cleaning'] = train_data['Description'].apply(clean_text)\n",
    "test_data['Text_cleaning'] = test_data['Description'].apply(clean_text)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###  Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data[\"Genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the style of seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting genre distribution horizontally\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.countplot(x='Genre', data=train_data, order=train_data['Genre'].value_counts().index)\n",
    "plt.title('Genre Distribution')\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform training data\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train_data['Text_cleaning'])\n",
    "\n",
    "# Transform test data\n",
    "tfidf_test = tfidf_vectorizer.transform(test_data['Text_cleaning'])\n",
    "\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform training data\n",
    "count_train = count_vectorizer.fit_transform(train_data['Text_cleaning'])\n",
    "\n",
    "# Transform test data\n",
    "count_test = count_vectorizer.transform(test_data['Text_cleaning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# import numpy as np\n",
    "#\n",
    "# # Assuming train_data['Text_cleaning'] contains preprocessed text data\n",
    "# sentences = [text.split() for text in train_data['Text_cleaning']]\n",
    "#\n",
    "# # Train Word2Vec model\n",
    "# word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "#\n",
    "# # Function to convert text to a fixed-length vector representation\n",
    "# def text_to_vector(text):\n",
    "#     words = text.split()\n",
    "#     vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "#     if vectors:\n",
    "#         return np.mean(vectors, axis=0)\n",
    "#     else:\n",
    "#         return np.zeros(word2vec_model.vector_size)  # Return zero vector if no words found in Word2Vec model\n",
    "#\n",
    "# # Convert train and test data to vectors\n",
    "# word2vec_train = np.array([text_to_vector(text) for text in train_data['Text_cleaning']])\n",
    "# word2vec_test = np.array([text_to_vector(text) for text in test_data['Text_cleaning']])\n",
    "\n",
    "# Now you can use these vectors with any classifier of your choice (e.g., Naive Bayes, SVM, etc.)\n",
    "# Train and evaluate the classifier using word2vec_train and word2vec_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_data['Genre'], predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_data['Genre'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier_count = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier_count.fit(count_train, train_data['Genre'])\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions_count = nb_classifier_count.predict(count_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_count = accuracy_score(test_data['Genre'], predictions_count)\n",
    "print(\"Accuracy with CountVectorizer:\", accuracy_count)\n",
    "\n",
    "# Get classification report\n",
    "print(\"\\nClassification Report with CountVectorizer:\")\n",
    "print(classification_report(test_data['Genre'], predictions_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# nb_classifier_word2vec = MultinomialNB()\n",
    "# nb_classifier_word2vec.fit(word2vec_train, train_data['Genre'])\n",
    "#\n",
    "# predictions_word2vec = nb_classifier_word2vec.predict(word2vec_test)\n",
    "#\n",
    "# accuracy_word2vec = accuracy_score(test_sol_data['Genre'], predictions_word2vec)\n",
    "# print(\"Accuracy with Word2Vec:\", accuracy_word2vec)\n",
    "#\n",
    "# print(\"\\nClassification Report with Word2Vec:\")\n",
    "# print(classification_report(test_sol_data['Genre'], predictions_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Initialize the KNN classifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "\n",
    "# Make predictions on the test data using KNN\n",
    "predictions_knn = knn_classifier.predict(tfidf_test)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "accuracy_knn = accuracy_score(test_data['Genre'], predictions_knn)\n",
    "print(\"\\nAccuracy (KNN):\", accuracy_knn)\n",
    "\n",
    "# Get classification report for KNN\n",
    "print(\"\\nClassification Report (KNN):\")\n",
    "print(classification_report(test_data['Genre'], predictions_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the KNN classifier\n",
    "knn_classifier_count = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier_count.fit(count_train, train_data['Genre'])\n",
    "\n",
    "# Make predictions on the test data using KNN\n",
    "predictions_knn_count = knn_classifier.predict(count_test)\n",
    "\n",
    "# Evaluate the KNN model\n",
    "accuracy_knn_count = accuracy_score(test_data['Genre'], predictions_knn_count)\n",
    "print(\"\\nAccuracy (KNN):\", accuracy_knn_count)\n",
    "\n",
    "# Get classification report for KNN\n",
    "print(\"\\nClassification Report (KNN):\")\n",
    "print(classification_report(test_data['Genre'], predictions_knn_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "# print('DecisionTreeClassifier')\n",
    "#\n",
    "# # Initialize the Decision Tree classifier\n",
    "# dt_classifier = DecisionTreeClassifier()\n",
    "#\n",
    "# # Train the Decision Tree classifier\n",
    "# dt_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "#\n",
    "# # Make predictions on the test data using Decision Tree\n",
    "# predictions_dt = dt_classifier.predict(tfidf_test)\n",
    "#\n",
    "# # Evaluate the Decision Tree model\n",
    "# accuracy_dt = accuracy_score(test_sol_data['Genre'], predictions_dt)\n",
    "# print(\"Accuracy (Decision Tree):\", accuracy_dt)\n",
    "#\n",
    "# # Get classification report for Decision Tree\n",
    "# print(\"\\nClassification Report (Decision Tree):\")\n",
    "# print(classification_report(test_sol_data['Genre'], predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Initialize the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier()\n",
    "#\n",
    "# # Train the Random Forest classifier\n",
    "# rf_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "#\n",
    "# # Make predictions on the test data using Random Forest\n",
    "# predictions_rf = rf_classifier.predict(tfidf_test)\n",
    "#\n",
    "# # Evaluate the Random Forest model\n",
    "# accuracy_rf = accuracy_score(test_sol_data['Genre'], predictions_rf)\n",
    "# print(\"\\nAccuracy (Random Forest):\", accuracy_rf)\n",
    "#\n",
    "# # Get classification report for Random Forest\n",
    "# print(\"\\nClassification Report (Random Forest):\")\n",
    "# print(classification_report(test_sol_data['Genre'], predictions_rf))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "#\n",
    "#\n",
    "# # Initialize the Logistic Regression classifier\n",
    "# lr_classifier = LogisticRegression(multi_class='multinomial',max_iter=100, solver='sag')\n",
    "#\n",
    "# # Train the Logistic Regression classifier\n",
    "# lr_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "#\n",
    "# # Make predictions on the test data using Logistic Regression\n",
    "# predictions_lr = lr_classifier.predict(tfidf_test)\n",
    "#\n",
    "# # Evaluate the Logistic Regression model\n",
    "# accuracy_lr = accuracy_score(test_sol_data['Genre'], predictions_lr)\n",
    "# print(\"Accuracy (Logistic Regression):\", accuracy_lr)\n",
    "#\n",
    "# # Get classification report for Logistic Regression\n",
    "# print(\"\\nClassification Report (Logistic Regression):\")\n",
    "# print(classification_report(test_sol_data['Genre'], predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print('svm')\n",
    "# # Initialize the SVM classifier\n",
    "# svm_classifier = SVC(kernel='linear')\n",
    "#\n",
    "# # Train the classifier\n",
    "# svm_classifier.fit(tfidf_train, train_data['Genre'])\n",
    "#\n",
    "# # Make predictions on the test data\n",
    "# predictions = svm_classifier.predict(tfidf_test)\n",
    "#\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(test_sol_data['Genre'], predictions)\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "#\n",
    "# # Get classification report\n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(test_sol_data['Genre'], predictions))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Movie Genre Classification)",
   "language": "python",
   "name": "pycharm-2d1458af"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
